{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75819c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.model_selection import train_test_split # for train-test split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler # for categorical encoding\n",
    "from sklearn.compose import ColumnTransformer # for combining transformations\n",
    "from sklearn.pipeline import Pipeline # for creating a pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report # for evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, brier_score_loss # for ROC curve and AUC\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from sklearn.model_selection import cross_val_predict # for cross-validation predictions\n",
    "from sklearn.linear_model import LogisticRegressionCV # for cross-validated logistic regression\n",
    "from sklearn.model_selection import StratifiedKFold # for stratified fold cross-validation\n",
    "from sklearn.base import clone # for cloning models\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold # for repeated stratified fold cross-validation\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4109fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load models\n",
    "ari_model = joblib.load(\"BAARD_arp_clin_model.joblib\")\n",
    "bup_model = joblib.load(\"BAARD_bup_clin_model.joblib\")\n",
    "\n",
    "# Expected features (from training). If your models have feature_names_in_, use those.\n",
    "ari_features = list(getattr(ari_model, \"feature_names_in_\", [])) or [\n",
    "    'age', 'sex', 'edu_lvl', 'baseline_madrs',  'BMI_extreme'  ,'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression'\n",
    "]\n",
    "bup_features = list(getattr(bup_model, \"feature_names_in_\", [])) or [\n",
    "   'age', 'sex', 'edu_lvl', 'baseline_madrs',  'BMI_extreme'  ,'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff23e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "master_df = pd.read_csv('C:\\\\Users\\\\Hassan\\\\Documents\\\\Projects\\\\baard\\\\baard_master_sheet.csv')\n",
    "\n",
    "\n",
    "# make variable had_fall if total_number_falls > 0\n",
    "master_df['had_fall'] = (master_df['total_number_falls'] > 0).astype(int)\n",
    "\n",
    "# add new varaible BMI_extremer, where 1 = bmi > 40 or < 20, binary variables\n",
    "master_df['BMI_extreme'] = ((master_df['bmi'] > 40) | (master_df['bmi'] < 20)).astype(int)\n",
    "\n",
    "master_df['sex'] = (master_df['gender'] == 'Male').astype(int)\n",
    "\n",
    "\n",
    "# filter out rows with missing values in the features we care about\n",
    "ON_arp = master_df[master_df['medication_group'] == \"ARIPIPRAZOLE\"]\n",
    "ON_arp = ON_arp.dropna(subset=['remission_status' ,'age', 'sex', 'edu_lvl', 'baseline_madrs',  'BMI_extreme'  ,'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression'])\n",
    "\n",
    "ON_bup = master_df[master_df['medication_group'] == \"BUPROPION\"]\n",
    "ON_bup = ON_bup.dropna(subset=['remission_status' ,'age', 'sex', 'edu_lvl', 'baseline_madrs',  'BMI_extreme'  ,'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e7d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(df, features, id_col=\"record_id\"):\n",
    "    X = df[features].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    mask = X.notna().all(axis=1)   # use your training-time imputer instead if you had one\n",
    "    return df.loc[mask, id_col].to_numpy(), X.loc[mask].to_numpy(), mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d1c834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUP (scored by ARI model) AUC: 0.6507057987204224\n",
      "BUP (scored by ARI model) Brier: 0.19240748915104927\n",
      "ARI (scored by BUP model) AUC: 0.561952861952862\n",
      "ARI (scored by BUP model) Brier: 0.2745601443434609\n"
     ]
    }
   ],
   "source": [
    "# --- ARI model → BUP cohort ---\n",
    "bup_ids, X_bup_for_ari, m_bup = build_matrix(ON_bup, ari_features)\n",
    "bup_probs_from_ari = ari_model.predict_proba(X_bup_for_ari)[:, 1]\n",
    "preds_bup_from_ari = pd.DataFrame({\n",
    "    \"record_id\": bup_ids,\n",
    "    \"prob_remission\": bup_probs_from_ari\n",
    "})\n",
    "# Optional evaluation if labels exist\n",
    "if \"remission_status\" in ON_bup.columns:\n",
    "    y_bup = ON_bup.loc[m_bup, \"remission_status\"].astype(int).to_numpy()\n",
    "    print(\"BUP (scored by ARI model) AUC:\", roc_auc_score(y_bup, bup_probs_from_ari))\n",
    "    print(\"BUP (scored by ARI model) Brier:\", brier_score_loss(y_bup, bup_probs_from_ari))\n",
    "\n",
    "# --- BUP model → ARI cohort ---\n",
    "ari_ids, X_ari_for_bup, m_ari = build_matrix(ON_arp, bup_features)\n",
    "ari_probs_from_bup = bup_model.predict_proba(X_ari_for_bup)[:, 1]\n",
    "preds_ari_from_bup = pd.DataFrame({\n",
    "    \"record_id\": ari_ids,\n",
    "    \"prob_remission\": ari_probs_from_bup\n",
    "})\n",
    "if \"remission_status\" in ON_arp.columns:\n",
    "    y_ari = ON_arp.loc[m_ari, \"remission_status\"].astype(int).to_numpy()\n",
    "    print(\"ARI (scored by BUP model) AUC:\", roc_auc_score(y_ari, ari_probs_from_bup))\n",
    "    print(\"ARI (scored by BUP model) Brier:\", brier_score_loss(y_ari, ari_probs_from_bup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e06a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ARI model → BUP cohort ---\n",
    "bup_ids, X_bup_for_ari, m_bup = build_matrix(ON_bup, ari_features)\n",
    "bup_probs_from_ari = ari_model.predict_proba(X_bup_for_ari)[:, 1]\n",
    "\n",
    "bup_out = (\n",
    "    pd.DataFrame({'record_id': bup_ids, 'prob_remission': bup_probs_from_ari})\n",
    "      .merge(ON_bup.loc[m_bup, ['record_id','age','sex','remission_status']],\n",
    "             on='record_id', how='left')\n",
    "      [['record_id','age','sex','remission_status','prob_remission']]\n",
    ")\n",
    "# Optional: clearer column name\n",
    "bup_out = bup_out.rename(columns={'prob_remission':'prob_remission_from_ARI_model'})\n",
    "\n",
    "# --- BUP model → ARI cohort ---\n",
    "ari_ids, X_ari_for_bup, m_ari = build_matrix(ON_arp, bup_features)  # <- your ARI cohort is ON_arp\n",
    "ari_probs_from_bup = bup_model.predict_proba(X_ari_for_bup)[:, 1]\n",
    "\n",
    "ari_out = (\n",
    "    pd.DataFrame({'record_id': ari_ids, 'prob_remission': ari_probs_from_bup})\n",
    "      .merge(ON_arp.loc[m_ari, ['record_id','age','sex','remission_status']],\n",
    "             on='record_id', how='left')\n",
    "      [['record_id','age','sex','remission_status','prob_remission']]\n",
    ")\n",
    "ari_out = ari_out.rename(columns={'prob_remission':'prob_remission_from_BUP_model'})\n",
    "\n",
    "# (Optional) combine and tag\n",
    "all_out = pd.concat([\n",
    "    bup_out.assign(group='BUP', scored_by='ARI_model'),\n",
    "    ari_out.assign(group='ARI', scored_by='BUP_model')\n",
    "], ignore_index=True)\n",
    "\n",
    "# (Optional) save\n",
    "bup_out.to_csv('preds_BUP_scored_by_ARI.csv', index=False)\n",
    "ari_out.to_csv('preds_ARI_scored_by_BUP.csv', index=False)\n",
    "# all_out.to_csv('preds_crosscohort_all.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fc60cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.27\n",
    "bup_out['y_pred'] = (bup_out['prob_remission_from_ARI_model'] >= threshold).astype(int)\n",
    "ari_out['y_pred'] = (ari_out['prob_remission_from_BUP_model'] >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6383cc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': np.int64(35), 'fp': np.int64(67), 'tn': np.int64(22), 'fn': np.int64(2), 'sensitivity': np.float64(0.9459459459459459), 'specificity': np.float64(0.24719101123595505)}\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1\n",
    "bup_out['y_pred'] = (bup_out['prob_remission_from_ARI_model'] >= threshold).astype(int)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(bup_out['remission_status'].astype(int),\n",
    "                                  bup_out['y_pred']).ravel()\n",
    "sens = tp/(tp+fn) if (tp+fn) else float('nan')\n",
    "spec = tn/(tn+fp) if (tn+fp) else float('nan')\n",
    "print(dict(tp=tp, fp=fp, tn=tn, fn=fn, sensitivity=sens, specificity=spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "12d71dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, brier_score_loss\n",
    "import numpy as np\n",
    "\n",
    "def threshold_report(df, prob_col, y_col='remission_status', thr=0.10):\n",
    "    y = df[y_col].astype(int).values\n",
    "    p = df[prob_col].values\n",
    "    yhat = (p >= thr).astype(int)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()\n",
    "    n = len(y); pos = int(y.sum()); neg = n - pos\n",
    "\n",
    "    acc  = (tp + tn) / n\n",
    "    sens = tp / (tp + fn) if (tp + fn) else np.nan\n",
    "    spec = tn / (tn + fp) if (tn + fp) else np.nan\n",
    "    prec = tp / (tp + fp) if (tp + fp) else np.nan\n",
    "    npv  = tn / (tn + fn) if (tn + fn) else np.nan\n",
    "    f1   = (2 * prec * sens / (prec + sens)) if (prec > 0 and sens > 0) else np.nan\n",
    "    bal  = 0.5 * (sens + spec)\n",
    "    auc  = roc_auc_score(y, p)\n",
    "    brier = brier_score_loss(y, p)\n",
    "\n",
    "    print(f\"\\nThreshold report @ thr = {thr:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"N={n} | Positives={pos} ({pos/n:.1%}) | Predicted +={tp+fp} ({(tp+fp)/n:.1%})\")\n",
    "    print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "    print(f\"               Pred 0   Pred 1\")\n",
    "    print(f\"True 0 ({neg:3d})   {tn:7d} {fp:8d}\")\n",
    "    print(f\"True 1 ({pos:3d})   {fn:7d} {tp:8d}\")\n",
    "    print(\"\\nMetrics:\")\n",
    "    print(f\"  Accuracy:           {acc:.3f}\")\n",
    "    print(f\"  Sensitivity (TPR):  {sens:.3f}\")\n",
    "    print(f\"  Specificity (TNR):  {spec:.3f}\")\n",
    "    print(f\"  Precision (PPV):    {prec:.3f}\")\n",
    "    print(f\"  NPV:                {npv:.3f}\")\n",
    "    print(f\"  Balanced Accuracy:  {bal:.3f}\")\n",
    "    print(f\"  F1 score:           {f1:.3f}\")\n",
    "    print(f\"  AUC (prob-based):   {auc:.3f}\")\n",
    "    print(f\"  Brier score:        {brier:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5be0b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold report @ thr = 0.10\n",
      "----------------------------------------\n",
      "N=126 | Positives=37 (29.4%) | Predicted +=102 (81.0%)\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "               Pred 0   Pred 1\n",
      "True 0 ( 89)        22       67\n",
      "True 1 ( 37)         2       35\n",
      "\n",
      "Metrics:\n",
      "  Accuracy:           0.452\n",
      "  Sensitivity (TPR):  0.946\n",
      "  Specificity (TNR):  0.247\n",
      "  Precision (PPV):    0.343\n",
      "  NPV:                0.917\n",
      "  Balanced Accuracy:  0.597\n",
      "  F1 score:           0.504\n",
      "  AUC (prob-based):   0.709\n",
      "  Brier score:        0.197\n",
      "\n",
      "Threshold report @ thr = 0.27\n",
      "----------------------------------------\n",
      "N=126 | Positives=37 (29.4%) | Predicted +=69 (54.8%)\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "               Pred 0   Pred 1\n",
      "True 0 ( 89)        49       40\n",
      "True 1 ( 37)         8       29\n",
      "\n",
      "Metrics:\n",
      "  Accuracy:           0.619\n",
      "  Sensitivity (TPR):  0.784\n",
      "  Specificity (TNR):  0.551\n",
      "  Precision (PPV):    0.420\n",
      "  NPV:                0.860\n",
      "  Balanced Accuracy:  0.667\n",
      "  F1 score:           0.547\n",
      "  AUC (prob-based):   0.709\n",
      "  Brier score:        0.197\n",
      "\n",
      "Threshold report @ thr = 0.29\n",
      "----------------------------------------\n",
      "N=126 | Positives=37 (29.4%) | Predicted +=67 (53.2%)\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "               Pred 0   Pred 1\n",
      "True 0 ( 89)        51       38\n",
      "True 1 ( 37)         8       29\n",
      "\n",
      "Metrics:\n",
      "  Accuracy:           0.635\n",
      "  Sensitivity (TPR):  0.784\n",
      "  Specificity (TNR):  0.573\n",
      "  Precision (PPV):    0.433\n",
      "  NPV:                0.864\n",
      "  Balanced Accuracy:  0.678\n",
      "  F1 score:           0.558\n",
      "  AUC (prob-based):   0.709\n",
      "  Brier score:        0.197\n",
      "\n",
      "Threshold report @ thr = 0.34\n",
      "----------------------------------------\n",
      "N=126 | Positives=37 (29.4%) | Predicted +=57 (45.2%)\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "               Pred 0   Pred 1\n",
      "True 0 ( 89)        57       32\n",
      "True 1 ( 37)        12       25\n",
      "\n",
      "Metrics:\n",
      "  Accuracy:           0.651\n",
      "  Sensitivity (TPR):  0.676\n",
      "  Specificity (TNR):  0.640\n",
      "  Precision (PPV):    0.439\n",
      "  NPV:                0.826\n",
      "  Balanced Accuracy:  0.658\n",
      "  F1 score:           0.532\n",
      "  AUC (prob-based):   0.709\n",
      "  Brier score:        0.197\n"
     ]
    }
   ],
   "source": [
    "threshold_report(bup_out, 'prob_remission_from_ARI_model', 'remission_status', thr=0.10)\n",
    "# e.g., also try the operating points you care about:\n",
    "for t in (0.27, 0.29, 0.34):\n",
    "    threshold_report(bup_out, 'prob_remission_from_ARI_model', thr=t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd415d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def sweep_thresholds(df, prob_col, y_col='remission_status'):\n",
    "    y = df[y_col].astype(int).values\n",
    "    p = df[prob_col].values\n",
    "    rows = []\n",
    "    for t in np.linspace(0, 1, 101):\n",
    "        yhat = (p >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()\n",
    "        sens = tp/(tp+fn) if (tp+fn) else np.nan\n",
    "        spec = tn/(tn+fp) if (tn+fp) else np.nan\n",
    "        prec = tp/(tp+fp) if (tp+fp) else np.nan\n",
    "        acc  = (tp+tn)/(tp+tn+fp+fn)\n",
    "        f1   = (2*prec*sens/(prec+sens)) if (prec>0 and sens>0) else np.nan\n",
    "        J    = sens + spec - 1\n",
    "        rows.append((t, acc, sens, spec, prec, f1, J, tp, fp, tn, fn))\n",
    "    return pd.DataFrame(rows, columns=[\n",
    "        'threshold','accuracy','sensitivity','specificity','precision','f1','youdenJ','tp','fp','tn','fn'\n",
    "    ])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84bc247",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sweep_thresholds(bup_out, 'prob_remission_from_ARI_model')\n",
    "# Example picks:\n",
    "t_J   = grid.loc[grid['youdenJ'].idxmax(), 'threshold']      # maximizes sensitivity+specificity\n",
    "t_F1  = grid.loc[grid['f1'].idxmax(), 'threshold']           # best F1\n",
    "t_s80 = grid.iloc[(grid['sensitivity']-0.80).abs().idxmin()]['threshold']  # ~80% sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b67409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sweep_thresholds(ari_out, 'prob_remission_from_BUP_model')\n",
    "# Example picks:\n",
    "t_J   = grid.loc[grid['youdenJ'].idxmax(), 'threshold']      # maximizes sensitivity+specificity\n",
    "t_F1  = grid.loc[grid['f1'].idxmax(), 'threshold']           # best F1\n",
    "t_s80 = grid.iloc[(grid['sensitivity']-0.80).abs().idxmin()]['threshold']  # ~80% sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e38c8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#left join mean_prob from ON_bup_cog_predictions.csv by record_id onto preds_BUP_scored_by_ARI.csv and name the mean_prob column to mean_prob(onbup)\n",
    "bup_out = bup_out.merge(\n",
    "    pd.read_csv('ON_bup_clin_predictions.csv')[['record_id', 'mean_prob']],\n",
    "    on='record_id', how='left'\n",
    ")\n",
    "bup_out = bup_out.rename(columns={'mean_prob': 'mean_prob(onbup)'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9b987b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# same for ARI\n",
    "ari_out = ari_out.merge(\n",
    "    pd.read_csv('ON_arp_clin_predictions.csv')[['record_id', 'mean_prob']],\n",
    "    on='record_id', how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "485b7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "ari_out = ari_out.rename(columns={'mean_prob': 'mean_prob(onari)'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a995b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat ari_out and bup_out\n",
    "all_out = pd.concat([bup_out, ari_out], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dd794d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_out.to_csv('preds_crosscohort_all_clin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f15a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "baard_cohort=pd.read_csv('C:\\\\Users\\\\Hassan\\\\Documents\\\\Projects\\\\baard\\\\BAARD_cohort_predictions_clinonly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0745b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join the column MEDICATION_GROUP from master_df onto baard_cohort by record_id\n",
    "baard_cohort = baard_cohort.merge(\n",
    "    master_df[['record_id', 'medication_group']],\n",
    "    on='record_id', how='left'\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b63a4",
   "metadata": {},
   "source": [
    "## adding threshold columns to baard coohort predicitons csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cfbfd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baard_cohort=pd.read_csv('C:\\\\Users\\\\Hassan\\\\Documents\\\\Projects\\\\baard\\\\BAARD_cohort_predictions.csv')\n",
    "\n",
    "baard_cohort = baard_cohort.loc[:, :'p(remission_on_bup)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e41611cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_35992\\303595855.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n"
     ]
    }
   ],
   "source": [
    "#make columns for the thresholds using p(remission_on_arp) and p(remission_on_bup) make a function that thresholdes from 0.1 to 0.9 in steps of 0.1\n",
    "def add_threshold_columns(df, prob_col, threshold_col_prefix='threshold'):\n",
    "    thresholds = np.arange(0.1, 1.0, 0.01)  # 0.10, 0.11, ..., 0.99\n",
    "    for t in thresholds:\n",
    "        df[f'{threshold_col_prefix}_{t:.2f}'] = (df[prob_col] >= t).astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "baard_cohort = add_threshold_columns(baard_cohort, 'p(remission_on_arp)', 'threshold_arp')\n",
    "baard_cohort = add_threshold_columns(baard_cohort, 'p(remission_on_bup)', 'threshold_bup')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68ccf35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record_id             NaN\n",
      "medication_group      NaN\n",
      "age                   NaN\n",
      "sex                   NaN\n",
      "remission_status      NaN\n",
      "                     ... \n",
      "threshold_bup_0.95      0\n",
      "threshold_bup_0.96      0\n",
      "threshold_bup_0.97      0\n",
      "threshold_bup_0.98      0\n",
      "threshold_bup_0.99      0\n",
      "Name: 127, Length: 187, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print row 127\n",
    "print(baard_cohort.iloc[127])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d053a813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9133858267716536' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.905511811023622' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8976377952755905' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.889763779527559' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8661417322834646' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.84251968503937' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.84251968503937' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.84251968503937' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.84251968503937' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8267716535433071' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8110236220472441' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7952755905511811' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7637795275590551' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7401574803149606' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7401574803149606' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6850393700787402' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6614173228346457' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6220472440944882' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6062992125984252' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6062992125984252' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6062992125984252' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5905511811023622' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5905511811023622' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5669291338582677' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5511811023622047' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5354330708661418' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5118110236220472' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5118110236220472' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5118110236220472' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4881889763779528' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.48031496062992124' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.48031496062992124' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.44881889763779526' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.41732283464566927' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.41732283464566927' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4015748031496063' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3779527559055118' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3700787401574803' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.36220472440944884' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.33858267716535434' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.31496062992125984' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.30708661417322836' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2992125984251969' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2755905511811024' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2755905511811024' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2677165354330709' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.25196850393700787' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2440944881889764' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2440944881889764' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.23622047244094488' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2283464566929134' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2283464566929134' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.1968503937007874' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.18110236220472442' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.1732283464566929' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.14173228346456693' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.14173228346456693' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.14173228346456693' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.13385826771653545' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.13385826771653545' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.13385826771653545' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.11811023622047244' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.11811023622047244' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.11811023622047244' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.11811023622047244' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.09448818897637795' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.09448818897637795' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.07086614173228346' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.06299212598425197' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05511811023622047' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05511811023622047' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05511811023622047' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05511811023622047' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.047244094488188976' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.03937007874015748' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.03937007874015748' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.031496062992125984' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.023622047244094488' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.023622047244094488' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.015748031496062992' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.015748031496062992' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.007874015748031496' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8661417322834646' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8346456692913385' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7874015748031497' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7795275590551181' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7401574803149606' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.7086614173228346' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6929133858267716' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6850393700787402' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6771653543307087' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6614173228346457' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.6377952755905512' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5905511811023622' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5905511811023622' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5826771653543307' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5669291338582677' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5354330708661418' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5354330708661418' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5275590551181102' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4881889763779528' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4645669291338583' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.44881889763779526' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.44881889763779526' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4251968503937008' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4094488188976378' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.4015748031496063' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3937007874015748' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3779527559055118' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.36220472440944884' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3464566929133858' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.31496062992125984' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.25196850393700787' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2204724409448819' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.2125984251968504' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.18110236220472442' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.1732283464566929' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.16535433070866143' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.14173228346456693' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.14173228346456693' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.12598425196850394' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.11811023622047244' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.10236220472440945' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.09448818897637795' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.08661417322834646' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.07086614173228346' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.07086614173228346' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.06299212598425197' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.06299212598425197' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.06299212598425197' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.05511811023622047' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.047244094488188976' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.047244094488188976' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.047244094488188976' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.047244094488188976' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.047244094488188976' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.03937007874015748' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.031496062992125984' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.031496062992125984' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.031496062992125984' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.031496062992125984' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.023622047244094488' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.023622047244094488' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.023622047244094488' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.023622047244094488' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.023622047244094488' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.023622047244094488' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.015748031496062992' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.015748031496062992' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.015748031496062992' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\102585320.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.007874015748031496' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baard_cohort.loc[row_idx, col] = proportion\n"
     ]
    }
   ],
   "source": [
    "row_idx = 127\n",
    "threshold_cols = [col for col in baard_cohort.columns if col.startswith(\"threshold_bup_\") or col.startswith(\"threshold_arp_\")]\n",
    "\n",
    "for col in threshold_cols:\n",
    "    if baard_cohort.loc[row_idx, col] == 0:\n",
    "        col_without_row = baard_cohort[col].drop(index=row_idx)\n",
    "        proportion = col_without_row.sum() / len(col_without_row)\n",
    "        baard_cohort.loc[row_idx, col] = proportion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a9d37e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify threshold columns\n",
    "arp_cols = sorted([c for c in baard_cohort.columns if c.startswith(\"threshold_arp_\")])\n",
    "bup_cols = sorted([c for c in baard_cohort.columns if c.startswith(\"threshold_bup_\")])\n",
    "\n",
    "# Interleave them\n",
    "interleaved_threshold_cols = []\n",
    "for a, b in zip(arp_cols, bup_cols):\n",
    "    interleaved_threshold_cols.extend([a, b])\n",
    "\n",
    "# Keep the non-threshold columns in original order\n",
    "non_threshold_cols = [c for c in baard_cohort.columns if c not in arp_cols + bup_cols]\n",
    "\n",
    "# Reorder DataFrame\n",
    "baard_cohort = baard_cohort[non_threshold_cols + interleaved_threshold_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a73d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "baard_cohort.to_csv('BAARD_cohort_predictions_threshold_clin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "585eeb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, brier_score_loss\n",
    "\n",
    "def sweep_metrics(df, prob_col, y_col, thresholds, model_label):\n",
    "    # keep only rows with valid prob + label\n",
    "    s = df[[prob_col, y_col]].copy()\n",
    "    s[prob_col] = pd.to_numeric(s[prob_col], errors='coerce')\n",
    "    s[y_col] = pd.to_numeric(s[y_col], errors='coerce')\n",
    "    s = s.dropna()\n",
    "    s = s[s[y_col].isin([0, 1])]\n",
    "\n",
    "    if len(s) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    y = s[y_col].astype(int).values\n",
    "    p = s[prob_col].astype(float).values\n",
    "\n",
    "    # prob-based metrics (constant across thresholds)\n",
    "    auc = roc_auc_score(y, p) if len(np.unique(y)) == 2 else np.nan\n",
    "    brier = brier_score_loss(y, p)\n",
    "\n",
    "    rows = []\n",
    "    for t in sorted(thresholds):\n",
    "        yhat = (p >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()\n",
    "        sens = tp/(tp+fn) if (tp+fn) else np.nan\n",
    "        spec = tn/(tn+fp) if (tn+fp) else np.nan\n",
    "        prec = tp/(tp+fp) if (tp+fp) else np.nan\n",
    "        npv  = tn/(tn+fn) if (tn+fn) else np.nan\n",
    "        acc  = (tp+tn)/(tp+tn+fp+fn)\n",
    "        f1   = (2*prec*sens/(prec+sens)) if (prec>0 and sens>0) else np.nan\n",
    "        bal  = 0.5*(sens+spec) if (not np.isnan(sens) and not np.isnan(spec)) else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"model\": model_label,\n",
    "            \"threshold\": float(t),\n",
    "            \"n\": len(y),\n",
    "            \"positives\": int(y.sum()),\n",
    "            \"predicted_positives\": int((yhat==1).sum()),\n",
    "            \"tp\": int(tp), \"fp\": int(fp), \"tn\": int(tn), \"fn\": int(fn),\n",
    "            \"accuracy\": acc, \"sensitivity\": sens, \"specificity\": spec,\n",
    "            \"precision\": prec, \"npv\": npv, \"f1\": f1, \"balanced_accuracy\": bal,\n",
    "            \"auc\": auc, \"brier\": brier\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# pull the exact thresholds from your existing columns\n",
    "arp_ts = {float(c.split('_')[-1]) for c in baard_cohort.columns if c.startswith(\"threshold_arp_\")}\n",
    "bup_ts = {float(c.split('_')[-1]) for c in baard_cohort.columns if c.startswith(\"threshold_bup_\")}\n",
    "# sensible fallbacks if not found\n",
    "if not arp_ts: arp_ts = set(np.arange(0.10, 1.00, 0.01))\n",
    "if not bup_ts: bup_ts = set(np.arange(0.10, 1.00, 0.01))\n",
    "\n",
    "# compute\n",
    "m_arp = sweep_metrics(baard_cohort, \"p(remission_on_arp)\", \"remission_status\", arp_ts, \"ARP_model\")\n",
    "m_bup = sweep_metrics(baard_cohort, \"p(remission_on_bup)\", \"remission_status\", bup_ts, \"BUP_model\")\n",
    "\n",
    "metrics = pd.concat([m_arp, m_bup], ignore_index=True)\n",
    "\n",
    "# save\n",
    "#out_path = \"baard_threshold_metrics_clin.csv\"\n",
    "#metrics.to_csv(out_path, index=False)\n",
    "#print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad6bfbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "baard_cohort = baard_cohort[~baard_cohort['record_id'].astype(str).str.startswith('CU')].dropna(subset=['remission_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23af29dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 threshold pairs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a20319a0-265a-42b8-a79a-2d5432b78317",
       "rows": [],
       "shape": {
        "columns": 0,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "def group_rates_at(df, t_arp, t_bup, y_col='remission_status',\n",
    "                   arp_p='p(remission_on_arp)', bup_p='p(remission_on_bup)'):\n",
    "    a1 = df[arp_p].astype(float) >= t_arp\n",
    "    b1 = df[bup_p].astype(float) >= t_bup\n",
    "    g1 = a1 & b1\n",
    "    g2 = (~a1) & b1\n",
    "    g3 = a1 & (~b1)\n",
    "    g4 = (~a1) & (~b1)\n",
    "\n",
    "    y = df[y_col].astype(int)\n",
    "\n",
    "    def n_and_rate(mask):\n",
    "        n = int(mask.sum())\n",
    "        r = float(y[mask].mean()) if n > 0 else np.nan\n",
    "        return n, r\n",
    "\n",
    "    n1, r1 = n_and_rate(g1)\n",
    "    n2, r2 = n_and_rate(g2)\n",
    "    n3, r3 = n_and_rate(g3)\n",
    "    n4, r4 = n_and_rate(g4)\n",
    "\n",
    "    # relative size difference (info only)\n",
    "    g23_rel_diff = (abs(n2 - n3) / max(n2, n3)) if max(n2, n3) > 0 else np.nan\n",
    "\n",
    "    return dict(t_arp=float(t_arp), t_bup=float(t_bup),\n",
    "                n1=n1, n2=n2, n3=n3, n4=n4,\n",
    "                r1=r1, r2=r2, r3=r3, r4=r4,\n",
    "                g23_rel_diff=g23_rel_diff)\n",
    "\n",
    "def find_threshold_pairs_no_eq(baard_cohort,\n",
    "                               g1_min=0.7, g23_min=0.15, g4_max=0.1,\n",
    "                               min_n_each=5,\n",
    "                               y_col='remission_status',\n",
    "                               arp_p='p(remission_on_arp)', bup_p='p(remission_on_bup)'):\n",
    "    arp_ts = sorted({float(c.replace('threshold_arp_', '')) \n",
    "                 for c in baard_cohort.columns if c.startswith('threshold_arp_')})\n",
    "    bup_ts = sorted({float(c.replace('threshold_bup_', '')) \n",
    "                 for c in baard_cohort.columns if c.startswith('threshold_bup_')})\n",
    "\n",
    "\n",
    "    rows = []\n",
    "    for ta in arp_ts:\n",
    "        for tb in bup_ts:\n",
    "            m = group_rates_at(baard_cohort, ta, tb, y_col=y_col, arp_p=arp_p, bup_p=bup_p)\n",
    "\n",
    "            # size floor\n",
    "            if any(m[k] < min_n_each for k in ('n1','n2','n3','n4')):\n",
    "                continue\n",
    "            # rate constraints\n",
    "            if not (m['r1'] >= g1_min): continue\n",
    "            if not (m['r2'] >= g23_min and m['r3'] >= g23_min): continue\n",
    "            if not (m['r4'] <= g4_max): continue\n",
    "\n",
    "            rows.append(m)\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    if out.empty:\n",
    "        return out\n",
    "\n",
    "    # Rank: prioritize higher min(r2,r3), then higher r1, then lower r4; show g23_rel_diff for context\n",
    "    out['min_r23'] = out[['r2','r3']].min(axis=1)\n",
    "    out = out.sort_values(['min_r23','r1','r4'], ascending=[False, False, True]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# Run it\n",
    "results = find_threshold_pairs_no_eq(\n",
    "    baard_cohort,\n",
    "    g1_min=0.75,\n",
    "    g23_min=0.65,   # tweak if you want stricter/looser for groups 2&3\n",
    "    g4_max=0.15,\n",
    "    min_n_each=5    # raise if you want to avoid tiny groups\n",
    ")\n",
    "\n",
    "print(f\"Found {len(results)} threshold pairs.\")\n",
    "results.head(10).round(3)\n",
    "\n",
    "# Save all candidates\n",
    "#results.to_csv(\"baard_threshold_pair_candidates_no_eq.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e95b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.25, 0.27, 0.24, 0.26, 0.28, 0.5, 0.75, 0.51, 0.76, 0.79, 0.84, 0.21, 0.23, 0.22, 0.54, 0.38, 0.63, 0.88, 0.47, 0.72, 0.97, 0.18, 0.19, 0.42, 0.43, 0.44, 0.2, 0.45, 0.46, 0.41, 0.92, 0.69, 0.94, 0.15, 0.16, 0.17, 0.55, 0.8, 0.39, 0.64, 0.89, 0.48, 0.73, 0.98, 0.57, 0.82, 0.12, 0.13, 0.14, 0.59, 0.67, 0.83, 0.35, 0.6, 0.68, 0.85, 0.93, 0.11, 0.52, 0.77, 0.91, 0.36, 0.61, 0.86, 0.7, 0.95, 0.1, 0.56, 0.81, 0.4, 0.65, 0.9, 0.49, 0.74, 0.99, 0.58, 0.34, 0.29, 0.3, 0.31, 0.32, 0.33, 0.53, 0.78, 0.37, 0.62, 0.87, 0.71, 0.96, 0.66}\n"
     ]
    }
   ],
   "source": [
    "print(arp_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "253f9a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(t_arp=0.41, t_bup=0.41)  G1 r=0.789 n=19 | G2 r=0.500 n=8 | G3 r=0.385 n=39 | G4 r=0.167 n=54\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def check_pair(df, t_arp=0.41, t_bup=0.41,\n",
    "               y_col='remission_status',\n",
    "               arp_p='p(remission_on_arp)', bup_p='p(remission_on_bup)'):\n",
    "    s = df[[arp_p, bup_p, y_col]].copy()\n",
    "    s[arp_p] = pd.to_numeric(s[arp_p], errors='coerce')\n",
    "    s[bup_p] = pd.to_numeric(s[bup_p], errors='coerce')\n",
    "    s[y_col] = pd.to_numeric(s[y_col], errors='coerce').astype('Int64')\n",
    "\n",
    "    s = s.dropna(subset=[arp_p, bup_p, y_col])\n",
    "    s[y_col] = s[y_col].astype(int)\n",
    "\n",
    "    a1 = s[arp_p] >= t_arp\n",
    "    b1 = s[bup_p] >= t_bup\n",
    "\n",
    "    g1 = s.loc[a1 & b1, y_col]\n",
    "    g2 = s.loc[(~a1) & b1, y_col]\n",
    "    g3 = s.loc[a1 & (~b1), y_col]\n",
    "    g4 = s.loc[(~a1) & (~b1), y_col]\n",
    "\n",
    "    def rr(x): \n",
    "        return (x.mean() if len(x) else np.nan, len(x))\n",
    "    r1,n1 = rr(g1); r2,n2 = rr(g2); r3,n3 = rr(g3); r4,n4 = rr(g4)\n",
    "\n",
    "    print(f\"(t_arp={t_arp:.2f}, t_bup={t_bup:.2f})  \"\n",
    "          f\"G1 r={r1:.3f} n={n1} | G2 r={r2:.3f} n={n2} | \"\n",
    "          f\"G3 r={r3:.3f} n={n3} | G4 r={r4:.3f} n={n4}\")\n",
    "\n",
    "check_pair(baard_cohort, 0.41, 0.41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "63a11d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact solutions found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top trade-offs (first rows):\n",
      "   t_arp  t_bup  n_g1   r_g1  n_g2  r_g2  n_g3   r_g3  n_g4   r_g4  min_r23\n",
      "0   0.34   0.41    21  0.762     6   0.5    45  0.378    48  0.146    0.378\n",
      "1   0.28   0.41    22  0.773     5   0.4    51  0.373    42  0.119    0.373\n",
      "2   0.29   0.41    22  0.773     5   0.4    51  0.373    42  0.119    0.373\n",
      "3   0.30   0.41    22  0.773     5   0.4    51  0.373    42  0.119    0.373\n",
      "4   0.33   0.41    22  0.773     5   0.4    46  0.370    47  0.149    0.370\n",
      "5   0.31   0.41    22  0.773     5   0.4    49  0.367    44  0.136    0.367\n",
      "6   0.32   0.41    22  0.773     5   0.4    49  0.367    44  0.136    0.367\n",
      "7   0.27   0.41    22  0.773     5   0.4    53  0.358    40  0.125    0.358\n",
      "8   0.34   0.40    24  0.750     6   0.5    42  0.357    48  0.146    0.357\n",
      "9   0.28   0.40    25  0.760     5   0.4    48  0.354    42  0.119    0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
      "C:\\Users\\Hassan\\AppData\\Local\\Temp\\ipykernel_62640\\3715535658.py:21: RuntimeWarning: All-NaN axis encountered\n",
      "  out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "def group_rates_at(df, t_arp, t_bup, y_col='remission_status',\n",
    "                   arp_p='p(remission_on_arp)', bup_p='p(remission_on_bup)'):\n",
    "    s = df[[arp_p, bup_p, y_col]].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "    y = s[y_col].astype(int)\n",
    "    a1 = s[arp_p] >= t_arp\n",
    "    b1 = s[bup_p] >= t_bup\n",
    "    masks = {\n",
    "        'g1': a1 & b1,\n",
    "        'g2': (~a1) & b1,\n",
    "        'g3': a1 & (~b1),\n",
    "        'g4': (~a1) & (~b1),\n",
    "    }\n",
    "    out = {'t_arp': float(t_arp), 't_bup': float(t_bup)}\n",
    "    for k, m in masks.items():\n",
    "        n = int(m.sum())\n",
    "        r = float(y[m].mean()) if n > 0 else np.nan\n",
    "        out[f'n_{k}'] = n\n",
    "        out[f'r_{k}'] = r\n",
    "    out['min_r23'] = np.nanmin([out['r_g2'], out['r_g3']])\n",
    "    return out\n",
    "\n",
    "def find_pairs(df, g1_min=0.75, g23_min=0.65, g4_max=0.15, min_n_each=5,\n",
    "               arp_p='p(remission_on_arp)', bup_p='p(remission_on_bup)'):\n",
    "    # dense numeric grid (ignore column names entirely)\n",
    "    thr = np.round(np.arange(0.10, 1.00, 0.01), 2)\n",
    "    rows = []\n",
    "    for ta in thr:\n",
    "        for tb in thr:\n",
    "            m = group_rates_at(df, ta, tb, arp_p=arp_p, bup_p=bup_p)\n",
    "            if any(m[k] < min_n_each for k in ('n_g1','n_g2','n_g3','n_g4')): \n",
    "                continue\n",
    "            if not (m['r_g1'] >= g1_min): continue\n",
    "            if not (m['r_g2'] >= g23_min and m['r_g3'] >= g23_min): continue\n",
    "            if not (m['r_g4'] <= g4_max): continue\n",
    "            rows.append(m)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def best_tradeoff(df, g1_min=0.75, g4_max=0.15, min_n_each=5,\n",
    "                  arp_p='p(remission_on_arp)', bup_p='p(remission_on_bup)'):\n",
    "    thr = np.round(np.arange(0.10, 1.00, 0.01), 2)\n",
    "    rows = []\n",
    "    for ta in thr:\n",
    "        for tb in thr:\n",
    "            m = group_rates_at(df, ta, tb, arp_p=arp_p, bup_p=bup_p)\n",
    "            if any(m[k] < min_n_each for k in ('n_g1','n_g2','n_g3','n_g4')): \n",
    "                continue\n",
    "            if not (m['r_g1'] >= g1_min): continue\n",
    "            if not (m['r_g4'] <= g4_max): continue\n",
    "            rows.append(m)\n",
    "    out = pd.DataFrame(rows)\n",
    "    if out.empty: return out\n",
    "    # rank: maximize min(G2,G3), then maximize r_g1, then minimize r_g4\n",
    "    return out.sort_values(['min_r23','r_g1','r_g4'],\n",
    "                           ascending=[False, False, True]).reset_index(drop=True)\n",
    "\n",
    "# 1) Try to meet your exact targets\n",
    "exact = find_pairs(baard_cohort, g1_min=0.75, g23_min=0.65, g4_max=0.15, min_n_each=5)\n",
    "print(f\"Exact solutions found: {len(exact)}\")\n",
    "if not exact.empty:\n",
    "    print(exact.head(10).round(3))\n",
    "\n",
    "# 2) If none, get best trade-off (keeps G1≥0.75 and G4≤0.15, maximizes min(G2,G3))\n",
    "trade = best_tradeoff(baard_cohort, g1_min=0.75, g4_max=0.15, min_n_each=5)\n",
    "print(\"Top trade-offs (first rows):\")\n",
    "print(trade.head(10).round(3))\n",
    "\n",
    "# Optional: save\n",
    "# exact.to_csv(\"baard_exact_pairs.csv\", index=False)\n",
    "# trade.to_csv(\"baard_best_tradeoffs.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e77831fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Group 2 by SIZE (no constraints):\n",
      "      t_arp  t_bup  n_g1  r_g1  n_g2   r_g2  n_g3  r_g3  n_g4   r_g4\n",
      "7380   0.92    0.1     0   NaN   104  0.394     0   NaN    16  0.125\n",
      "7470   0.93    0.1     0   NaN   104  0.394     0   NaN    16  0.125\n",
      "7560   0.94    0.1     0   NaN   104  0.394     0   NaN    16  0.125\n",
      "7650   0.95    0.1     0   NaN   104  0.394     0   NaN    16  0.125\n",
      "7740   0.96    0.1     0   NaN   104  0.394     0   NaN    16  0.125\n",
      "7830   0.97    0.1     0   NaN   104  0.394     0   NaN    16  0.125\n",
      "7920   0.98    0.1     0   NaN   104  0.394     0   NaN    16  0.125\n",
      "8010   0.99    0.1     0   NaN   104  0.394     0   NaN    16  0.125\n",
      "7110   0.89    0.1     1   1.0   103  0.388     0   NaN    16  0.125\n",
      "7200   0.90    0.1     1   1.0   103  0.388     0   NaN    16  0.125\n",
      "\n",
      "Top Group 2 by REMISSION RATE (no constraints, require n_g2>=5):\n",
      "      t_arp  t_bup  n_g1  r_g1  n_g2  r_g2  n_g3  r_g3  n_g4   r_g4\n",
      "7425   0.92   0.55     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "7426   0.92   0.56     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "7427   0.92   0.57     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "7515   0.93   0.55     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "7516   0.93   0.56     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "7517   0.93   0.57     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "7605   0.94   0.55     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "7606   0.94   0.56     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "7607   0.94   0.57     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "7695   0.95   0.55     0   NaN     7   1.0     0   NaN   113  0.319\n",
      "\n",
      "Top Group 2 by SIZE (with constraints):\n",
      "      t_arp  t_bup  n_g1   r_g1  n_g2   r_g2  n_g3  r_g3  n_g4   r_g4\n",
      "4790   0.63   0.30    15  0.800    40  0.400     5   0.6    60  0.200\n",
      "4791   0.63   0.31    15  0.800    40  0.400     5   0.6    60  0.200\n",
      "4700   0.62   0.30    17  0.824    38  0.368     5   0.6    60  0.200\n",
      "4701   0.62   0.31    17  0.824    38  0.368     5   0.6    60  0.200\n",
      "4792   0.63   0.32    15  0.800    37  0.405     5   0.6    63  0.206\n",
      "4976   0.65   0.36    10  0.800    36  0.472     5   0.8    69  0.203\n",
      "5066   0.66   0.36    10  0.800    36  0.472     5   0.8    69  0.203\n",
      "5156   0.67   0.36    10  0.800    36  0.472     5   0.8    69  0.203\n",
      "4883   0.64   0.33    14  0.857    36  0.417     5   0.6    65  0.200\n",
      "4793   0.63   0.33    14  0.857    36  0.417     6   0.5    64  0.203\n",
      "\n",
      "Top Group 2 by REMISSION RATE (with constraints, n_g2>=5):\n",
      "      t_arp  t_bup  n_g1   r_g1  n_g2   r_g2  n_g3   r_g3  n_g4   r_g4\n",
      "4901   0.64   0.51     6  1.000     5  0.800    13  0.692    96  0.250\n",
      "4902   0.64   0.52     5  1.000     5  0.800    14  0.714    96  0.250\n",
      "4811   0.63   0.51     6  1.000     5  0.800    14  0.643    95  0.253\n",
      "4812   0.63   0.52     5  1.000     5  0.800    15  0.667    95  0.253\n",
      "4900   0.64   0.50     6  1.000     6  0.667    13  0.692    95  0.253\n",
      "4810   0.63   0.50     6  1.000     6  0.667    14  0.643    94  0.255\n",
      "4981   0.65   0.41     7  0.857    20  0.650     8  0.750    85  0.212\n",
      "5071   0.66   0.41     7  0.857    20  0.650     8  0.750    85  0.212\n",
      "5161   0.67   0.41     7  0.857    20  0.650     8  0.750    85  0.212\n",
      "5251   0.68   0.41     7  0.857    20  0.650     7  0.714    86  0.221\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# ---- run it ----\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m grid_results \u001b[38;5;241m=\u001b[39m scan_grid(baard_cohort)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# All possible outcomes (no mins, no constraints), but requiring readings in G2, G3, G4\u001b[39;00m\n\u001b[0;32m     94\u001b[0m g1_ranked \u001b[38;5;241m=\u001b[39m best_group1_allgroups(grid_results)\n",
      "Cell \u001b[1;32mIn[47], line 33\u001b[0m, in \u001b[0;36mscan_grid\u001b[1;34m(df, grid)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ta \u001b[38;5;129;01min\u001b[39;00m grid:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tb \u001b[38;5;129;01min\u001b[39;00m grid:\n\u001b[1;32m---> 33\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend(group_stats(df, ta, tb))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\n",
      "Cell \u001b[1;32mIn[47], line 9\u001b[0m, in \u001b[0;36mgroup_stats\u001b[1;34m(df, t_arp, t_bup, y_col, arp_p, bup_p)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgroup_stats\u001b[39m(df, t_arp, t_bup, y_col\u001b[38;5;241m=\u001b[39mYCOL, arp_p\u001b[38;5;241m=\u001b[39mARP_P, bup_p\u001b[38;5;241m=\u001b[39mBUP_P):\n\u001b[1;32m----> 9\u001b[0m     s \u001b[38;5;241m=\u001b[39m df[[arp_p, bup_p, y_col]]\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_numeric, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     10\u001b[0m     y \u001b[38;5;241m=\u001b[39m s[y_col]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     11\u001b[0m     a1 \u001b[38;5;241m=\u001b[39m s[arp_p] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m t_arp\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4117\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   4115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 4117\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[0;32m   4120\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[0;32m   4121\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[0;32m   4122\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[0;32m   4123\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[0;32m   4124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[0;32m   4125\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indices\u001b[38;5;241m=\u001b[39mindices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4131\u001b[0m     )\n\u001b[1;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   4134\u001b[0m     indices,\n\u001b[0;32m   4135\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[0;32m   4136\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   4137\u001b[0m )\n\u001b[0;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4140\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    895\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[0;32m    896\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[0;32m    897\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    898\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    899\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    900\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:788\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    785\u001b[0m     blknos \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos, slobj, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill\n\u001b[0;32m    787\u001b[0m     )\n\u001b[1;32m--> 788\u001b[0m     blklocs \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs, slobj, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill\n\u001b[0;32m    790\u001b[0m     )\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# When filling blknos, make sure blknos is updated before appending to\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;66;03m# blocks list, that way new blkno is exactly len(blocks).\u001b[39;00m\n\u001b[0;32m    794\u001b[0m blocks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32mc:\\Users\\Hassan\\anaconda3\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ARP_P = 'p(remission_on_arp)'\n",
    "BUP_P = 'p(remission_on_bup)'\n",
    "YCOL  = 'remission_status'\n",
    "\n",
    "def group_stats(df, t_arp, t_bup, y_col=YCOL, arp_p=ARP_P, bup_p=BUP_P):\n",
    "    s = df[[arp_p, bup_p, y_col]].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "    y = s[y_col].astype(int)\n",
    "    a1 = s[arp_p] >= t_arp\n",
    "    b1 = s[bup_p] >= t_bup\n",
    "    masks = {\n",
    "        'g1': a1 & b1,\n",
    "        'g2': (~a1) & b1,\n",
    "        'g3': a1 & (~b1),\n",
    "        'g4': (~a1) & (~b1),\n",
    "    }\n",
    "    out = {'t_arp': float(t_arp), 't_bup': float(t_bup)}\n",
    "    for k, m in masks.items():\n",
    "        n = int(m.sum())\n",
    "        r = float(y[m].mean()) if n > 0 else np.nan\n",
    "        out[f'n_{k}'] = n\n",
    "        out[f'r_{k}'] = r\n",
    "    return out\n",
    "\n",
    "def scan_grid(df, grid=None):\n",
    "    if grid is None:\n",
    "        grid = np.round(np.arange(0.10, 1.00, 0.01), 2)  # 0.10..0.99\n",
    "    rows = []\n",
    "    for ta in grid:\n",
    "        for tb in grid:\n",
    "            rows.append(group_stats(df, ta, tb))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def apply_constraints(res,\n",
    "                      g1_min=None, g23_min=None, g4_max=None,\n",
    "                      min_n_each=None):\n",
    "    mask = pd.Series(True, index=res.index)\n",
    "    if min_n_each is not None:\n",
    "        mask &= (res[['n_g1','n_g2','n_g3','n_g4']] >= min_n_each).all(axis=1)\n",
    "    if g1_min is not None:\n",
    "        mask &= res['r_g1'] >= g1_min\n",
    "    if g23_min is not None:\n",
    "        mask &= (res['r_g2'] >= g23_min) & (res['r_g3'] >= g23_min)\n",
    "    if g4_max is not None:\n",
    "        mask &= res['r_g4'] <= g4_max\n",
    "    return res[mask].copy()\n",
    "\n",
    "def best_group2_by_size(res):\n",
    "    return res.sort_values(['n_g2','r_g2','r_g1','r_g4'],\n",
    "                           ascending=[False, False, False, True]).head(10)\n",
    "\n",
    "def best_group2_by_rate(res, min_n2=5):\n",
    "    r = res[res['n_g2'] >= min_n2]\n",
    "    return r.sort_values(['r_g2','n_g2','r_g1','r_g4'],\n",
    "                         ascending=[False, False, False, True]).head(10)\n",
    "\n",
    "# ---- run it ----\n",
    "grid_results = scan_grid(baard_cohort)\n",
    "\n",
    "# (A) Unconstrained: biggest Group 2 and highest Group 2 remission\n",
    "print(\"Top Group 2 by SIZE (no constraints):\")\n",
    "print(best_group2_by_size(grid_results).round(3))\n",
    "\n",
    "print(\"\\nTop Group 2 by REMISSION RATE (no constraints, require n_g2>=5):\")\n",
    "print(best_group2_by_rate(grid_results, min_n2=5).round(3))\n",
    "\n",
    "# (B) With your earlier goals as constraints (tweak as needed):\n",
    "constrained = apply_constraints(grid_results,\n",
    "                                g1_min=0.75,   # keep G1 high\n",
    "                                g23_min=None,  # drop G2/G3 min if you want pure G2 focus\n",
    "                                g4_max=None,   # keep G4 low\n",
    "                                min_n_each=5)  # avoid tiny groups\n",
    "\n",
    "print(\"\\nTop Group 2 by SIZE (with constraints):\")\n",
    "print(best_group2_by_size(constrained).round(3))\n",
    "\n",
    "print(\"\\nTop Group 2 by REMISSION RATE (with constraints, n_g2>=5):\")\n",
    "print(best_group2_by_rate(constrained, min_n2=5).round(3))\n",
    "\n",
    "\n",
    "def best_group1_allgroups(res):\n",
    "    # keep only combos where every group has at least one subject\n",
    "    r = res[(res[['n_g1','n_g2','n_g3','n_g4']] > 0).all(axis=1)].copy()\n",
    "    # rank by best G1 remission; tie-break by larger G1, then lower G4 remission\n",
    "    r = r.sort_values(['r_g1', 'n_g1', 'r_g4'], ascending=[False, False, True])\n",
    "    return r\n",
    "\n",
    "# ---- run it ----\n",
    "grid_results = scan_grid(baard_cohort)\n",
    "\n",
    "# All possible outcomes (no mins, no constraints), but requiring readings in G2, G3, G4\n",
    "g1_ranked = best_group1_allgroups(grid_results)\n",
    "\n",
    "print(\"All threshold pairs with non-empty G1..G4, ranked by Group 1 remission:\")\n",
    "print(g1_ranked.round(3))   # prints ALL rows, ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d11745",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results.to_csv(\"BAARD_threshold_grid_modality.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08590209",
   "metadata": {},
   "source": [
    "##Plot auc curves all in one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
