{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn.model_selection import train_test_split # for train-test split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler # for categorical encoding\n",
    "from sklearn.compose import ColumnTransformer # for combining transformations\n",
    "from sklearn.pipeline import Pipeline # for creating a pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report # for evaluation metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve # for ROC curve and AUC\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from sklearn.model_selection import cross_val_predict # for cross-validation predictions\n",
    "from sklearn.linear_model import LogisticRegressionCV # for cross-validated logistic regression\n",
    "from sklearn.model_selection import StratifiedKFold # for stratified fold cross-validation\n",
    "from sklearn.base import clone # for cloning models\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold # for repeated stratified fold cross-validation\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "master_df = pd.read_csv('C:\\\\Users\\\\Hassan\\\\Documents\\\\Projects\\\\baard\\\\baard_master_sheet.csv')\n",
    "\n",
    "\n",
    "# make variable had_fall if total_number_falls > 0\n",
    "master_df['had_fall'] = (master_df['total_number_falls'] > 0).astype(int)\n",
    "\n",
    "# add new varaible BMI_extremer, where 1 = bmi > 40 or < 20, binary variables\n",
    "master_df['BMI_extreme'] = ((master_df['bmi'] > 40) | (master_df['bmi'] < 20)).astype(int)\n",
    "\n",
    " \n",
    "ON_both = master_df[master_df['medication_group'].isin([\"ARIPIPRAZOLE\", \"BUPROPION\"])]\n",
    "\n",
    "ON_arp = master_df[master_df['medication_group'] == \"ARIPIPRAZOLE\"]\n",
    "\n",
    "ON_bup = master_df[master_df['medication_group'] == \"BUPROPION\"]\n",
    "\n",
    "\n",
    "###### prepare the data for modeling #########\n",
    "\n",
    "\n",
    "## new clin demo variables = age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status',  'mini_6', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme',\n",
    "                ## add to models and see difference\n",
    "\n",
    "ON_bup_cog = ON_bup.dropna(subset=['MTOTALIS_01'])\n",
    "ON_bup_cog = ON_bup_cog[~ON_bup_cog['record_id'].str.startswith('CU')]\n",
    "#select the demographic columns and cog columns\n",
    "ON_bup_cog = ON_bup_cog[['record_id','age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status',  'mini_6', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme', 'AIS_01',\t'MDMIS_01',\t'LIS_01',\t'MVCIS_01',\t'IMIS_01',\t'MTOTALIS_01','CWI3CSSFinal_01','DERRSS4_01','CWI4CSSFinal_01','DTMT4ER_01','DTMT4CO_01','DTMT4_01','DTMTS4_01','RCS_Z_01',\t'RDS_Z_01',\t'RFC_Z_01',\t'RFR_Z_01',\t'RLO_Z_01',\t'RLL_Z_01',\t'RREC_Z_01'\t,'PICTURE_Z_01',\t'RSR_Z_01',\t'RSF_Z_01'\t,'RSM_Z_01']].dropna()\n",
    "ON_arp_cog = ON_arp.dropna(subset=['MTOTALIS_01'])\n",
    "ON_arp_cog = ON_arp_cog[['record_id','age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status',  'mini_6', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme', 'AIS_01',\t'MDMIS_01',\t'LIS_01',\t'MVCIS_01',\t'IMIS_01',\t'MTOTALIS_01','CWI3CSSFinal_01','DERRSS4_01','CWI4CSSFinal_01','DTMT4ER_01','DTMT4CO_01','DTMT4_01','DTMTS4_01','RCS_Z_01',\t'RDS_Z_01',\t'RFC_Z_01',\t'RFR_Z_01',\t'RLO_Z_01',\t'RLL_Z_01',\t'RREC_Z_01'\t,'PICTURE_Z_01',\t'RSR_Z_01',\t'RSF_Z_01'\t,'RSM_Z_01']].dropna()\n",
    "\n",
    "ON_arp_cog = ON_arp_cog[~ON_arp_cog['record_id'].str.startswith('CU')]\n",
    "\n",
    "## prepare the data for modeling -- demographic variables + clin + nih cog\n",
    "\n",
    "ON_bup_nih =ON_bup.dropna(subset=['fcc_baseline'])\n",
    "ON_bup_nih = ON_bup_nih[~ON_bup_nih['record_id'].str.startswith('CU')]\n",
    "ON_bup_nih = ON_bup_nih[['record_id','age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status',  'mini_6', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme', 'fcc_baseline',\t'dccs_baseline',\t'flanker_baseline',\t'listSort_baseline',\t'pattComp_baseline'\t,'psm_baseline']].dropna()\n",
    "\n",
    "\n",
    "\n",
    "ON_arp_nih =ON_arp.dropna(subset=['fcc_baseline'])\n",
    "ON_arp_nih = ON_arp_nih[~ON_arp_nih['record_id'].str.startswith('CU')]\n",
    "ON_arp_nih = ON_arp_nih[['record_id','age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status',  'mini_6', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme', 'fcc_baseline',\t'dccs_baseline',\t'flanker_baseline',\t'listSort_baseline',\t'pattComp_baseline'\t,'psm_baseline']]\n",
    "\n",
    "#select the demographic columns and cog columns\n",
    "ON_arp_cog = ON_arp_cog[['record_id','age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status',  'mini_6', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme', 'AIS_01',\t'MDMIS_01',\t'LIS_01',\t'MVCIS_01',\t'IMIS_01',\t'MTOTALIS_01','CWI3CSSFinal_01','DERRSS4_01','CWI4CSSFinal_01','DTMT4ER_01','DTMT4CO_01','DTMT4_01','DTMTS4_01','RCS_Z_01',\t'RDS_Z_01',\t'RFC_Z_01',\t'RFR_Z_01',\t'RLO_Z_01',\t'RLL_Z_01',\t'RREC_Z_01'\t,'PICTURE_Z_01',\t'RSR_Z_01',\t'RSF_Z_01'\t,'RSM_Z_01']]\n",
    "\n",
    "## prepare the data for modeling -- demographis + clin + blood \n",
    "ON_bup_blood = ON_bup[['record_id','age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status',  'mini_6', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme','IL-6_sqrt', 'gp130_sqrt', 'IL-8/CXCL8_sqrt', 'uPAR_sqrt', 'MIF_sqrt',\n",
    "        'CCL2/JE/MCP-1_sqrt', 'Osteoprotegerin/TNFRSF11B_sqrt', 'IL-1 beta/IL-1F2_sqrt',\n",
    "        'CCL20/MIP-3 alpha_sqrt', 'CCL3/MIP-1 alpha_sqrt', 'CCL4/MIP-1 beta_sqrt',\n",
    "        'CCL13/MCP-4_sqrt', 'GM-CSF_sqrt', 'ICAM-1/CD54_sqrt', 'TNF RII/TNFRSF1B_sqrt',\n",
    "        'TNF RI/TNFRSF1A_sqrt', 'PIGF_sqrt', 'CXCL1/GRO alpha/KC/CINC-1_sqrt',\n",
    "        'IGFBP-2_sqrt', 'TIMP-1_sqrt', 'IGFBP-6_sqrt', 'Angiogenin_sqrt']].dropna()\n",
    "ON_bup_blood = ON_bup_blood[~ON_bup_blood['record_id'].str.startswith('CU')]\n",
    "ON_arp_blood = ON_arp[['record_id','age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status','IL-6_sqrt', 'gp130_sqrt', 'IL-8/CXCL8_sqrt', 'uPAR_sqrt', 'MIF_sqrt',\n",
    "        'CCL2/JE/MCP-1_sqrt', 'Osteoprotegerin/TNFRSF11B_sqrt', 'IL-1 beta/IL-1F2_sqrt',\n",
    "        'CCL20/MIP-3 alpha_sqrt', 'CCL3/MIP-1 alpha_sqrt', 'CCL4/MIP-1 beta_sqrt',\n",
    "        'CCL13/MCP-4_sqrt', 'GM-CSF_sqrt', 'ICAM-1/CD54_sqrt', 'TNF RII/TNFRSF1B_sqrt',\n",
    "        'TNF RI/TNFRSF1A_sqrt', 'PIGF_sqrt', 'CXCL1/GRO alpha/KC/CINC-1_sqrt',\n",
    "        'IGFBP-2_sqrt', 'TIMP-1_sqrt', 'IGFBP-6_sqrt', 'Angiogenin_sqrt']].dropna()\n",
    "ON_arp_blood = ON_arp_blood[~ON_arp_blood['record_id'].str.startswith('CU')]\n",
    "\n",
    "## prepare the data for modeling -- demographic variables + smri\n",
    "ON_bup_smri = ON_bup.dropna(subset=['Right.Amygdala_etiv'])\n",
    "# select the demographics and smri columns\n",
    "ON_bup_smri = ON_bup_smri[['record_id','age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status',  'mini_6', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme'\n",
    "\n",
    "] + list(ON_bup_smri.loc[:, 'WM.hypointensities_log':'Default_to_DorsAttn'].columns)] # change Right.Amygdala_etiv to DorsAttn, to get smri in addition to basic within network connectivity or Default_to_DorsAttn to get within network and network by network\n",
    "\n",
    "ON_arp_smri = ON_arp.dropna(subset=['Right.Amygdala_etiv'])\n",
    "# select the demographics and smri columns\n",
    "ON_arp_smri = ON_arp_smri[['record_id','age', 'gender', 'edu_lvl', 'baseline_madrs', 'remission_status',  'mini_6', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme'] + list(ON_arp_smri.loc[:, 'WM.hypointensities_log':'Default_to_DorsAttn'].columns)] # change Right.Amygdala_etiv to DorsAttn, to get smri in addition to basic within network connectivity or Default_to_DorsAttn to get within network and network by network\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ON_bup_cog_smri = ON_bup.dropna(subset=['MTOTALIS_01', 'Right.Amygdala_etiv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run correlations between variables just in case\n",
    "print(\"Correlation between :\", df['mini_6'].corr(df['years_with_depression']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression with Elastic Net Regularization (mri + clin)\n",
    "\n",
    "    # change l1 ratio, higher is ridge - so less 0s. change C to 50 -- 100, split just ct and then volumes or both -- see what performs better\n",
    "    ## np.arange(5.0, 15.5, 0.5).tolist() do this to grid search over C\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = ON_bup_cog.copy()\n",
    "df['sex'] = (df['gender'] == 'Male').astype(int)\n",
    "df['mini_addtl_q1'] = pd.to_numeric(df['mini_addtl_q1'], errors='coerce')\n",
    "# in mini 6 remove non numerical values\n",
    "#df['mini_6'] = pd.to_numeric(df['mini_6'], errors='coerce')\n",
    "# drop na values\n",
    "df = df.dropna(subset=['mini_addtl_q1', ])\n",
    "df = df[['record_id','age', 'sex', 'edu_lvl', 'baseline_madrs', 'remission_status',   'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme','AIS_01', 'CWI3CSSFinal_01', 'LIS_01', 'CWI4CSSFinal_01']].dropna()\n",
    "\n",
    "X = df[[ 'age', 'sex', 'edu_lvl', 'baseline_madrs', 'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme','AIS_01', 'CWI3CSSFinal_01', 'LIS_01', 'CWI4CSSFinal_01']].values\n",
    "y = df['remission_status'].astype(int).values\n",
    "feature_names = [ 'age', 'sex', 'edu_lvl', 'baseline_madrs',  'mini_addtl_q1','athf_f1_total_trials_v2','years_with_depression','BMI_extreme','AIS_01', 'CWI3CSSFinal_01', 'LIS_01', 'CWI4CSSFinal_01'  ]\n",
    "\n",
    "\n",
    "#  config for the model\n",
    "test_ratio = 0.20\n",
    "n_splits = 50 # number of repeated random splits\n",
    "threshold = 0.27 # threshold for classification, 0.27 is the threshold where sensitivity and specificity are balanced\n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_ratio, random_state=42)\n",
    "\n",
    "# Storage\n",
    "all_y_true = []\n",
    "all_y_scores = []\n",
    "all_y_pred = []\n",
    "coef_list = []\n",
    "fold_metrics = []\n",
    "per_fold_preds = []\n",
    "\n",
    "# loop over outter folds\n",
    "for fold_num, (train_idx, test_idx) in enumerate(sss.split(X, y)):\n",
    "    print(f\"Iteration {fold_num+1}/{n_splits} — Train size: {len(train_idx)}, Test size: {len(test_idx)}\")\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    test_ids = df.iloc[test_idx]['record_id'].values\n",
    "\n",
    "    clf = LogisticRegressionCV(\n",
    "        penalty='elasticnet',\n",
    "        solver='saga',\n",
    "        Cs=[10],\n",
    "        cv=4,\n",
    "        l1_ratios=[0.1] ,\n",
    "        scoring='neg_log_loss',\n",
    "        max_iter=1000000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_score >= threshold).astype(int)\n",
    "\n",
    "    # Store true/pred/scores\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_scores.extend(y_score)\n",
    "    all_y_pred.extend(y_pred)\n",
    "    coef_list.append(clf.coef_.flatten())\n",
    "\n",
    "    # Confusion matrix per fold\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) else 0\n",
    "    fold_auc = roc_auc_score(y_test, y_score)\n",
    "    # find balanced accuracy\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "\n",
    "\n",
    "\n",
    "    fold_metrics.append({\n",
    "        'iteration': fold_num + 1,\n",
    "        'TP': tp, 'FP': fp, 'TN': tn, 'FN': fn,\n",
    "        'Accuracy': accuracy,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'AUC': fold_auc,\n",
    "        'Balanced Accuracy': balanced_accuracy\n",
    "    })\n",
    "    # NEW: save per-fold predictions with record_id\n",
    "    per_fold_preds.append(pd.DataFrame({\n",
    "        'iteration': fold_num + 1,\n",
    "        'record_id': test_ids,\n",
    "        'y_true': y_test,\n",
    "        'y_score': y_score,       # probability of remission\n",
    "        'y_pred': y_pred\n",
    "    }))\n",
    "\n",
    "# Compute ROC curve on pooled predictions\n",
    "fpr, tpr, thresholds = roc_curve(all_y_true, all_y_scores)\n",
    "\n",
    "# Find threshold where sensitivity ≈ specificity\n",
    "specificity = 1 - fpr\n",
    "diff = np.abs(tpr - specificity)\n",
    "best_idx = np.argmin(diff)\n",
    "balanced_threshold = thresholds[best_idx]\n",
    "\n",
    "print(f\"\\nBalanced Sensitivity/Specificity threshold: {balanced_threshold:.3f}\")\n",
    "\n",
    "print(f\"Sensitivity: {tpr[best_idx]:.3f}, Specificity: {specificity[best_idx]:.3f}\")\n",
    "\n",
    "\n",
    "print(f'Balanced Accuracy: {balanced_accuracy:.3f}')\n",
    "\n",
    "\n",
    "#  metrics\n",
    "df_metrics = pd.DataFrame(fold_metrics)\n",
    "df_coefs = pd.DataFrame(coef_list, columns=feature_names)\n",
    "\n",
    "# average balanced accuracy\n",
    "average_balanced_accuracy = df_metrics['Balanced Accuracy'].mean()\n",
    "print(f\"Average Balanced Accuracy: {average_balanced_accuracy:.3f}\")\n",
    "\n",
    "#  pooled results\n",
    "pooled_auc = roc_auc_score(all_y_true, all_y_scores)\n",
    "fpr, tpr, _ = roc_curve(all_y_true, all_y_scores)\n",
    "\n",
    "print(f\"\\nPooled AUC: {pooled_auc:.3f}\")\n",
    "print(\"\\nAverage per-fold metrics:\")\n",
    "print(df_metrics[['Accuracy', 'Sensitivity', 'Specificity', 'AUC']].mean())\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Pooled ROC (AUC = {pooled_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Clin+sMRI+Cog response({n_splits} Iterations, 4 fold-CV, ON Bupropion group (n={len(df)})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot distribution of AUC scores across folds with mean and ±1 SD lines\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_metrics['AUC'], kde=True, bins=20, color='skyblue')\n",
    "\n",
    "# Mean and ±1 SD lines\n",
    "mean_auc = df_metrics['AUC'].mean()\n",
    "std_auc = df_metrics['AUC'].std()\n",
    "\n",
    "plt.axvline(mean_auc, color='blue', linestyle='--', label=f\"Mean AUC = {mean_auc:.3f}\")\n",
    "plt.axvline(mean_auc + std_auc, color='gray', linestyle='--', label='+1 SD')\n",
    "plt.axvline(mean_auc - std_auc, color='gray', linestyle='--', label='-1 SD')\n",
    "\n",
    "plt.title(\"Distribution of AUC Scores Across 100 Splits\")\n",
    "plt.xlabel(\"AUC\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output results -- coefs, metrics, preds, model\n",
    "\n",
    "df_coefs.to_csv(\"ON_arp_nih_coefs.csv\", index=False)\n",
    "\n",
    "# make fold metrics a DataFrame\n",
    "df_metrics = pd.DataFrame(fold_metrics)\n",
    "\n",
    "df_metrics.to_csv('bup_clin_per_fold_metrics.csv', index=False)\n",
    "\n",
    "df_preds = pd.concat(per_fold_preds, ignore_index=True)\n",
    "\n",
    "oof_by_id = (df_preds.groupby('record_id', as_index=False)\n",
    "             .agg(mean_prob=('y_score','mean'),\n",
    "                  std_prob=('y_score','std'),\n",
    "                  times_tested=('y_score','size'),\n",
    "                  y_true=('y_true','first'))\n",
    "             .sort_values('mean_prob', ascending=False))\n",
    "# oof_by_id has exactly one row per record_id with their OOS probability\n",
    "\n",
    "\n",
    "# save results\n",
    "oof_by_id.to_csv('ON_bup_cog_predictions.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# save the model\n",
    "joblib.dump(clf, 'BAARD_bup_clin_model.joblib')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = ON_arp_nih.copy() \n",
    "df['sex'] = (df['gender'] == 'Male').astype(int)\n",
    "#df['mini_addtl_q1'] = pd.to_numeric(df['mini_addtl_q1'], errors='coerce')\n",
    "# in mini 6 remove non numerical values\n",
    "#df['mini_6'] = pd.to_numeric(df['mini_6'], errors='coerce')\n",
    "# drop na values\n",
    "#df = df.dropna(subset=['mini_addtl_q1', ])\n",
    "df = df[['record_id','remission_status','age', 'sex', 'edu_lvl', 'baseline_madrs', 'fcc_baseline',\t'dccs_baseline',\t'flanker_baseline',\t'listSort_baseline',\t'pattComp_baseline'\t,'psm_baseline']].dropna()\n",
    "\n",
    "# Configuration\n",
    "test_ratio = 0.20\n",
    "n_splits = 10\n",
    "threshold = 0.35\n",
    "sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_ratio, random_state=42)\n",
    "feature_set_names = [ 'fcc_baseline',\t'dccs_baseline',\t'flanker_baseline',\t'listSort_baseline',\t'pattComp_baseline'\t,'psm_baseline']\n",
    "\n",
    "# Storage for ROC curves\n",
    "roc_results = {}\n",
    "\n",
    "for feature_name in feature_set_names:\n",
    "    print(f\"\\n=== Running model using feature: {feature_name} ===\")\n",
    "    \n",
    "    X = df[['age', 'sex', 'edu_lvl', 'baseline_madrs',    feature_name]].values\n",
    "    y = df['remission_status'].astype(int).values\n",
    "    feature_names = ['age', 'sex', 'edu_lvl', 'baseline_madrs',   feature_name]\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_scores = []\n",
    "\n",
    "    for fold_num, (train_idx, test_idx) in enumerate(sss.split(X, y)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        clf = LogisticRegressionCV(\n",
    "            penalty='elasticnet',\n",
    "            solver='saga',\n",
    "            Cs=10,\n",
    "            cv=6,\n",
    "            l1_ratios=[0.1],\n",
    "            scoring='neg_log_loss',\n",
    "            max_iter=1000000,\n",
    "            refit=True\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_scores.extend(y_score)\n",
    "\n",
    "    pooled_auc = roc_auc_score(all_y_true, all_y_scores)\n",
    "    fpr, tpr, _ = roc_curve(all_y_true, all_y_scores)\n",
    "\n",
    "    roc_results[feature_name] = {\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'auc': pooled_auc\n",
    "    }\n",
    "\n",
    "# === BASELINE MODEL: Demographics + baseline MADRS only ===\n",
    "print(\"\\n=== Running baseline model: age + sex + edu_lvl + baseline_madrs ===\")\n",
    "\n",
    "X_base = df[['age', 'sex', 'edu_lvl', 'baseline_madrs']].values\n",
    "y_base = df['remission_status'].astype(int).values\n",
    "\n",
    "all_y_true_base = []\n",
    "all_y_scores_base = []\n",
    "\n",
    "for fold_num, (train_idx, test_idx) in enumerate(sss.split(X_base, y_base)):\n",
    "    X_train_base, X_test_base = X_base[train_idx], X_base[test_idx]\n",
    "    y_train_base, y_test_base = y_base[train_idx], y_base[test_idx]\n",
    "\n",
    "    clf_base = LogisticRegressionCV(\n",
    "        penalty='elasticnet',\n",
    "        solver='saga',\n",
    "        Cs=10,\n",
    "        cv=4,\n",
    "        l1_ratios=[0.1],\n",
    "        scoring='neg_log_loss',\n",
    "        max_iter=1000000,\n",
    "        refit=True\n",
    "    )\n",
    "    clf_base.fit(X_train_base, y_train_base)\n",
    "\n",
    " \n",
    "\n",
    "    y_score_base = clf_base.predict_proba(X_test_base)[:, 1]\n",
    "    all_y_true_base.extend(y_test_base)\n",
    "    all_y_scores_base.extend(y_score_base)\n",
    "\n",
    "# Compute ROC and AUC for baseline model\n",
    "pooled_auc_base = roc_auc_score(all_y_true_base, all_y_scores_base)\n",
    "fpr_base, tpr_base, _ = roc_curve(all_y_true_base, all_y_scores_base)\n",
    "\n",
    "roc_results['Clinical only'] = {\n",
    "    'fpr': fpr_base,\n",
    "    'tpr': tpr_base,\n",
    "    'auc': pooled_auc_base\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot all ROC curves together\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "\n",
    "from itertools import cycle\n",
    "colors = cycle(plt.cm.tab10.colors + plt.cm.Set2.colors + plt.cm.Dark2.colors)\n",
    "\n",
    "for feature_name, result in roc_results.items():\n",
    "    plt.plot(result['fpr'], result['tpr'],\n",
    "             label=f'{feature_name} (AUC = {result[\"auc\"]:.2f})',\n",
    "             linewidth=2,\n",
    "             color=next(colors))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'Clin + neurocog predicting remission ({n_splits} Iterations, 10 fold-CV, Bup group n={len(df)})', fontsize=20)\n",
    "\n",
    "plt.legend(fontsize =20)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "suicide_modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
